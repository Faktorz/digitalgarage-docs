[[install-config-upgrading-automated-upgrades]]
<<<<<<< HEAD
= Performing Automated In-place Cluster Upgrades
{product-author}
{product-version}
:latest-tag: v3.3.1.3
=======
= Performing Automated Cluster Upgrades
{product-author}
{product-version}
>>>>>>> openshift/online
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

== Overview

<<<<<<< HEAD
If you installed using the
=======
ifdef::openshift-enterprise[]
Starting with OpenShift 3.0.2,
endif::[]
ifdef::openshift-origin[]
Starting with Origin 1.0.6,
endif::[]
if you installed using the
>>>>>>> openshift/online
xref:../../install_config/install/advanced_install.adoc#install-config-install-advanced-install[advanced installation]
and the inventory file that was used is available, you can use the upgrade
playbook to automate the OpenShift cluster upgrade process.
ifdef::openshift-enterprise[]
If you installed using the
xref:../../install_config/install/quick_install.adoc#install-config-install-quick-install[quick installation] method
and a *_~/.config/openshift/installer.cfg.yml_* file is available, you can use
the installer to perform the automated upgrade.
endif::[]

The automated upgrade performs the following steps for you:

* Applies the latest configuration.
* Upgrades and restart master services.
* Upgrades and restart node services.
* Applies the latest cluster policies.
* Updates the default router if one exists.
* Updates the default registry if one exists.
* Updates default image streams and InstantApp templates.

[IMPORTANT]
====
Ensure that you have met all
xref:../../install_config/install/prerequisites.adoc#install-config-install-prerequisites[prerequisites]
before proceeding with an upgrade. Failure to do so can result in a failed
upgrade.
====

ifdef::openshift-origin[]
[[running-upgrade-playbooks]]
== Running Upgrade Playbooks

Ensure that you have the latest *openshift-ansible* code checked out:

----
# cd ~/openshift-ansible
# git pull https://github.com/openshift/openshift-ansible master
----

Then run one of the following upgrade playbooks utilizing the inventory file you
used during the advanced installation. If your inventory file is located
somewhere other than the default *_/etc/ansible/hosts_*, add the `-i` flag to
specify the location.

[[upgrading-to-openshift-origin-1-1]]
=== Upgrading to OpenShift Origin 1.1

To upgrade from OpenShift Origin 1.0 to 1.1, run the following playbook:

----
# ansible-playbook \
    [-i </path/to/inventory/file>] \
    playbooks/byo/openshift-cluster/upgrades/v3_0_to_v3_1/upgrade.yml
----

[NOTE]
====
The *_v3_0_to_v3_1_* in the above path is a reference to the related OpenShift
Enterprise versions, however it is also the correct playbook to use when
upgrading from OpenShift Origin 1.0 to 1.1.
====

When the upgrade finishes, a recommendation will be printed to reboot all hosts.
<<<<<<< HEAD
After rebooting, continue to Updating Master and Node
Certificates.
=======
After rebooting, continue to Updating Master and Node Certificates.
>>>>>>> openshift/online

[[upgrading-to-openshift-origin-1-1-z-releases]]
=== Upgrading to OpenShift Origin 1.1.z Releases

To upgrade an existing OpenShift Origin 1.1 cluster to the latest 1.1.z release,
run the following playbook:

----
# ansible-playbook \
    [-i </path/to/inventory/file>] \
    playbooks/byo/openshift-cluster/upgrades/v3_1_minor/upgrade.yml
----

[NOTE]
====
The *v3_1_minor* in the above path is a reference to the related OpenShift
Enterprise versions, however it is also the correct playbook to use when
upgrading from OpenShift Origin 1.1 to the latest 1.1.z release.
====

When the upgrade finishes, a recommendation will be printed to reboot all hosts.
After rebooting, continue to xref:verifying-the-upgrade[Verifying the Upgrade].
endif::[]

ifdef::openshift-enterprise[]
[[preparing-for-an-automated-upgrade]]
== Preparing for an Automated Upgrade

<<<<<<< HEAD
[IMPORTANT]
====
Before upgrading your cluster to {product-title} 3.3, the cluster must be
already upgraded to the
link:https://docs.openshift.com/enterprise/3.2/release_notes/ose_3_2_release_notes.html#ose-32-asynchronous-errata-updates[latest asynchronous release of version 3.2]. Cluster upgrades cannot span more than one
=======
[NOTE]
====
Before upgrading your cluster to {product-title} 3.3, the cluster must be
already upgraded to the
link:https://docs.openshift.com/enterprise/3.2/release_notes/ose_3_2_release_notes.adoc#ose-32-asynchronous-errata-updates[latest asynchronous release of version 3.2]. Cluster upgrades cannot span more than one
>>>>>>> openshift/online
minor version at a time, so if your cluster is at version 3.0 or 3.1, you must
first upgrade incrementally (e.g., 3.0 to 3.1, then 3.1 or 3.2).
====

<<<<<<< HEAD
To prepare for an automated upgrade:

. If you are upgrading from version 3.2 to 3.3, manually disable the 3.2 channel and enable the 3.3 channel on each master and node host:
+
----
# subscription-manager repos --disable="rhel-7-server-ose-3.2-rpms" \
    --enable="rhel-7-server-ose-3.3-rpms"\
    --enable="rhel-7-server-extras-rpms"
# yum clean all
----
. For any upgrade path, always ensure that you have the latest version of the
*atomic-openshift-utils* package, which should also update the
*openshift-ansible-** packages:
+
----
# yum update atomic-openshift-utils
----
. Lastly, you must be logged in as a cluster administrative user on the master
host for the upgrade to succeed:
+
----
$ oc login
----

After satisfying these steps, there are two methods for running the automated
upgrade:

- xref:upgrading-using-the-installation-utility-to-upgrade[Using the installer]
- xref:running-the-upgrade-playbook-directly[Running the upgrade playbook directly]

Choose and follow one of these methods.
=======
[IMPORTANT]
====
Starting with
xref:../../release_notes/ose_3_2_release_notes.adoc#ose-32-relnotes-rhba-2016-1208[RHBA-2016:1208],
upgrades from {product-title} 3.1 to 3.2 are supported for clusters using the
containerized installation method. See
xref:../../release_notes/ose_3_2_release_notes.adoc#ose-32-known-issues[Known
Issues].
====

If you are upgrading from OpenShift Enterprise 3.1 to 3.2, on each master and
node host you must manually disable the 3.1 channel and enable the 3.2 channel:

====
----
# subscription-manager repos --disable="rhel-7-server-ose-3.1-rpms" \
    --enable="rhel-7-server-ose-3.2-rpms"\
    --enable="rhel-7-server-extras-rpms"
# yum clean all
----
====

For any upgrade path, always ensure that you have the latest version of the
*atomic-openshift-utils* package, which should also update the
*openshift-ansible-** packages:

----
# yum update atomic-openshift-utils
----

There are two methods for running the automated upgrade:
xref:upgrading-using-the-installation-utility-to-upgrade[using the installer]
or xref:running-the-upgrade-playbook-directly[running the upgrade playbook
directly]. Choose and follow one method.
>>>>>>> openshift/online

[[upgrading-using-the-installation-utility-to-upgrade]]
== Using the Installer to Upgrade

<<<<<<< HEAD
If you installed {product-title} using the
=======
If you installed OpenShift using the
>>>>>>> openshift/online
xref:../../install_config/install/quick_install.adoc#install-config-install-quick-install[quick installation] method,
you should have an installation configuration file located at
*_~/.config/openshift/installer.cfg.yml_*. The installer requires this file to
start an upgrade.

The installer supports upgrading between minor versions of {product-title}
(one minor version at a time, e.g., 3.2 to 3.3) as well as between
xref:../../release_notes/ocp_3_3_release_notes.adoc#ocp-33-asynchronous-errata-updates[asynchronous errata updates] within a minor version (e.g., 3.3.z).

If you have an older format installation configuration file in
<<<<<<< HEAD
*_~/.config/openshift/installer.cfg.yml_* from an installation of a previous
cluster version, the installer will attempt to upgrade the file to the new supported
format. If you do not have an installation configuration file of any format, you
can
xref:../../install_config/install/quick_install.adoc#defining-an-installation-configuration-file[create one manually].

To start an upgrade with the quick installer:

. Satisfy the steps in xref:preparing-for-an-automated-upgrade[Preparing for an Automated Upgrade] to ensure you are using the latest upgrade playbooks.
. Run the installer with the `upgrade` subcommand:
+
----
# atomic-openshift-installer upgrade
----
. Then, follow the on-screen instructions to upgrade to the latest release.
// tag::automated_upgrade_after_reboot[]
. When the upgrade finishes, a recommendation will be printed to reboot all hosts.
After rebooting, if there are no additional features enabled, you can
xref:verifying-the-upgrade[verify the upgrade]. Otherwise, the next step depends
on what features are enabled.
+
[cols="1,4"]
|===
| Feature | Next Step

| Aggregated Logging
| xref:automated-upgrading-efk-logging-stack[Upgrade the EFK logging stack.]

| Cluster Metrics
| xref:automated-upgrading-cluster-metrics[Upgrade cluster metrics.]
|===
// end::automated_upgrade_after_reboot[]
=======
*_~/.config/openshift/installer.cfg.yml_* from an existing OpenShift Enterprise
3.0 or 3.1 installation, the installer will attempt to upgrade the file to the
new supported format. If you do not have an installation configuration file of
any format, you can
xref:../../install_config/install/quick_install.adoc#defining-an-installation-configuration-file[create
one manually].

To start the upgrade, run the installer with the `upgrade` subcommand:

----
# atomic-openshift-installer upgrade
----

Then, follow the on-screen instructions to upgrade to the latest release. When
the upgrade finishes, a recommendation will be printed to reboot all hosts.
After rebooting, continue to
xref:automated-upgrading-efk-logging-stack[Upgrading the EFK Logging Stack] if
you have aggregated logging enabled, otherwise proceed to
xref:verifying-the-upgrade[Verifying the Upgrade].
>>>>>>> openshift/online

[[running-the-upgrade-playbook-directly]]
== Running the Upgrade Playbook Directly

<<<<<<< HEAD
You can run the automated upgrade playbook using Ansible directly, similar
to the advanced installation method, if you have an inventory file.

The same *_v3_3_* upgrade playbook can be used to upgrade either of the
following to the latest 3.3 release:

- xref:upgrading-to-ocp-3-3[Existing {product-title} 3.2 clusters]
- xref:upgrading-to-ocp-3-3-asynchronous-releases[Existing {product-title} 3.3 clusters]

[[upgrading-to-ocp-3-3]]
=== Upgrading to {product-title} 3.3

To run an upgrade from {product-title} 3.2 to 3.3:

. Satisfy the steps in xref:preparing-for-an-automated-upgrade[Preparing for an Automated Upgrade] to ensure you are using the latest upgrade playbooks.
. Ensure the `*deployment_type*` parameter in your inventory file is set to
`openshift-enterprise`.
. If you have multiple masters configured and want to enable rolling, full system
restarts of the hosts, you can set the `*openshift_rolling_restart_mode*`
parameter in your inventory file to `system`. Otherwise, the default value
*services* performs rolling service restarts on HA masters, but does not reboot
the systems. See
xref:../install/advanced_install.adoc#configuring-cluster-variables[Configuring
Cluster Variables] for details.
. Run the *_v3_3_* upgrade playbook. If your inventory file is located somewhere
other than the default *_/etc/ansible/hosts_*, add the `-i` flag to specify the
location. If you previously used the `atomic-openshift-installer` command to run
your installation, you can check *_~/.config/openshift/hosts_* (previously
located at *_~/.config/openshift/.ansible/hosts_*) for the last inventory file
that was used, if needed.
+
----
# ansible-playbook [-i </path/to/inventory/file>] \
    /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/upgrades/v3_3/upgrade.yml
----
include::install_config/upgrading/automated_upgrades.adoc[tag=automated_upgrade_after_reboot]

[[upgrading-to-ocp-3-3-asynchronous-releases]]
=== Upgrading to {product-title} 3.3 Asynchronous Releases

To apply
xref:../../release_notes/ocp_3_3_release_notes.html#ocp-33-asynchronous-errata-updates[asynchronous errata updates] to an existing {product-title} 3.3 cluster:


. Satisfy the steps in xref:preparing-for-an-automated-upgrade[Preparing for an Automated Upgrade] to ensure you are using the latest upgrade playbooks.
. Run the *_v3_3_* upgrade playbook (the same playbook that is used for
xref:upgrading-to-ocp-3-3[upgrading from {product-title} 3.2 to 3.3]). If your
inventory file is located somewhere other than the default
*_/etc/ansible/hosts_*, add the `-i` flag to specify the location. If you
previously used the `atomic-openshift-installer` command to run your
installation, you can check *_~/.config/openshift/hosts_* (previously located at
*_~/.config/openshift/.ansible/hosts_*) for the last inventory file that was
used, if needed.
+
=======
Alternatively, you can run the upgrade playbook with Ansible directly, similar
to the advanced installation method, if you have an inventory file.

[[upgrading-to-openshift-enterprise-3-2-0]]
=== Upgrading to OpenShift Enterprise 3.2.0

Before running the upgrade, first ensure the `*deployment_type*` parameter in
your inventory file is set to `openshift-enterprise`.

If you have multiple masters configured and want to enable rolling, full system
restarts of the hosts, you can set the `*openshift_rolling_restart_mode*`
parameter in your inventory file to `system`. Otherwise, the default value
`services` performs rolling service restarts on HA masters, but does not reboot
the systems. See
xref:../install/advanced_install.adoc#configuring-cluster-variables[Configuring
Cluster Variables] for details.

Then, run the *_v3_1_to_v3_2_* upgrade playbook. If your inventory file is
located somewhere other than the default *_/etc/ansible/hosts_*, add the `-i`
flag to specify the location. If you previously used the
`atomic-openshift-installer` command to run your installation, you can check
*_~/.config/openshift/.ansible/hosts_* for the last inventory file that was
used, if needed.

----
# ansible-playbook [-i </path/to/inventory/file>] \
    /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/upgrades/v3_1_to_v3_2/upgrade.yml
----

include::install_config/upgrading/automated_upgrades.adoc[tag=automated_upgrade_after_reboot]

[[upgrading-to-openshift-enterprise-3-3-asynchronous-releases]]
=== Upgrading to OpenShift Enterprise 3.3 Asynchronous Releases

To apply
xref:../../release_notes/ocp_3_3_release_notes.html#ocp-33-asynchronous-errata-updates[asynchronous errata updates] to an existing {product-title} 3.3 cluster, first upgrade the
*atomic-openshift-utils* package on the Red Hat Enterprise Linux 7 system where
you will be running Ansible:

----
# yum update atomic-openshift-utils
----

Then, run the same *_v3_3_* upgrade playbook that is used for
xref:upgrading-to-openshift-enterprise-3-3[upgrading to {product-title} 3.3 from
3.2]. If your inventory file is located somewhere other than the default
*_/etc/ansible/hosts_*, add the `-i` flag to specify the location. If you
previously used the `atomic-openshift-installer` command to run your
installation, you can check *_~/.config/openshift/hosts_* (previously located at
*_~/.config/openshift/.ansible/hosts_*) for the last
inventory file that was used, if needed.

>>>>>>> openshift/online
----
# ansible-playbook [-i </path/to/inventory/file>] \
    /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/upgrades/v3_3/upgrade.yml
----
<<<<<<< HEAD
include::install_config/upgrading/automated_upgrades.adoc[tag=automated_upgrade_after_reboot]
=======

[IMPORTANT]
====
The xref:../../install_config/upgrading/manual_upgrades.adoc#install-config-upgrading-manual-upgrades[manual upgrade
steps] are currently only applicable for
xref:../../install_config/install/rpm_vs_containerized.adoc#install-config-install-rpm-vs-containerized[RPM-based
installations]. Manual upgrade steps for
xref:../../install_config/install/rpm_vs_containerized.adoc#install-config-install-rpm-vs-containerized[containerized
installations] or clusters with mixed use of both RPM-based and containerized
hosts will be added soon in a documentation update.
====
>>>>>>> openshift/online
endif::[]

ifdef::openshift-origin[]
:sect: automated
include::install_config/upgrading/manual_upgrades.adoc[tag=30to31updatingcerts]
endif::[]

[[automated-upgrading-efk-logging-stack]]
== Upgrading the EFK Logging Stack

If you have previously xref:../../install_config/aggregate_logging.adoc#install-config-aggregate-logging[deployed
the EFK logging stack] and want to upgrade to the latest logging component
images, the steps must be performed manually as shown in
xref:../../install_config/upgrading/manual_upgrades.adoc#manual-upgrading-efk-logging-stack[Manual
Upgrades].

<<<<<<< HEAD
[[automated-upgrading-cluster-metrics]]
== Upgrading Cluster Metrics

If you have previously
xref:../../install_config/cluster_metrics.adoc#install-config-cluster-metrics[deployed cluster metrics],
you must manually
xref:../../install_config/upgrading/manual_upgrades.adoc#manual-upgrading-cluster-metrics[update]
to the latest metric components.

[[verifying-the-upgrade]]
== Verifying the Upgrade

To verify the upgrade:

. First check that all nodes are marked as *Ready*:
+
----
# oc get nodes
NAME                        STATUS                     AGE
master.example.com          Ready,SchedulingDisabled   165d
node1.example.com           Ready                      165d
node2.example.com           Ready                      165d
----
. Then, verify that you are running the expected versions of the *docker-registry*
and *router* images, if deployed.
ifdef::openshift-enterprise[]
Replace `<tag>` with `{latest-tag}` for the latest version.
endif::[]
+
----
ifdef::openshift-enterprise[]
# oc get -n default dc/docker-registry -o json | grep \"image\"
    "image": "openshift3/ose-docker-registry:<tag>",
# oc get -n default dc/router -o json | grep \"image\"
    "image": "openshift3/ose-haproxy-router:<tag>",
=======
[[verifying-the-upgrade]]
== Verifying the Upgrade

To verify the upgrade, first check that all nodes are marked as *Ready*:

====
----
# oc get nodes
NAME                 LABELS                                                                STATUS
master.example.com   kubernetes.io/hostname=master.example.com,region=infra,zone=default   Ready
node1.example.com    kubernetes.io/hostname=node1.example.com,region=primary,zone=east     Ready
----
====

Then, verify that you are running the expected versions of the *docker-registry*
and *router* images, if deployed:

====
----
ifdef::openshift-enterprise[]
# oc get -n default dc/docker-registry -o json | grep \"image\"
    "image": "openshift3/ose-docker-registry:v3.2.1.4",
# oc get -n default dc/router -o json | grep \"image\"
    "image": "openshift3/ose-haproxy-router:v3.2.1.4",
>>>>>>> openshift/online
endif::[]
ifdef::openshift-origin[]
# oc get -n default dc/docker-registry -o json | grep \"image\"
    "image": "openshift/origin-docker-registry:v1.0.6",
# oc get -n default dc/router -o json | grep \"image\"
    "image": "openshift/origin-haproxy-router:v1.0.6",
endif::[]
----
<<<<<<< HEAD
ifdef::openshift-origin[]
. If you upgraded from Origin 1.0 to Origin 1.1, verify in your old
=======
====

ifdef::openshift-origin[]
If you upgraded from Origin 1.0 to Origin 1.1, verify in your old
>>>>>>> openshift/online
*_/etc/sysconfig/openshift-master_* and *_/etc/sysconfig/openshift-node_* files
that any custom configuration is added to your new
*_/etc/sysconfig/origin-master_* and *_/etc/sysconfig/origin-node_* files.
endif::[]
<<<<<<< HEAD
. After upgrading, you can use the diagnostics tool on the master to look for
common issues:
+
=======

After upgrading, you can use the diagnostics tool on the master to look for
common issues:

====
>>>>>>> openshift/online
----
# oadm diagnostics
...
[Note] Summary of diagnostics execution:
[Note] Completed with no errors or warnings seen.
----
<<<<<<< HEAD
=======
====
>>>>>>> openshift/online
