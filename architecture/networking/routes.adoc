[[architecture-core-concepts-routes]]
= Routes
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:prewrap!:

toc::[]

== Overview

An {product-title} route exposes a
xref:pods_and_services.adoc#services[service] at a
host name, like _www.example.com_, so that external clients can reach it by
name.

DNS resolution for a host name is handled separately from routing.
Your administrator may have configured a
ifdef::openshift-online,digital-garage,openshift-dedicated[]
DNS wildcard entry
endif::[]
ifdef::openshift-origin,openshift-enterprise[]
xref:../../install_config/install/prerequisites.adoc#prereq-dns[DNS wildcard entry]
endif::[]
that will resolve to the {product-title} node that is running the
{product-title} router. If you are using a different host name you may
need to modify its DNS records independently to resolve to the node that
is running the router.

Each route consists of a name (limited to 63 characters), a service selector,
and an optional security configuration.

[[routers]]
include::architecture/topics/routers.adoc[]

[[routes-template-routers]]

include::architecture/topics/template_routers.adoc[]

[[available-router-plug-ins]]

== Available Router Plug-ins

The following router plug-ins are provided and supported in {product-title}.
ifdef::openshift-enterprise,openshift-origin[]
Instructions on deploying these routers are available in
xref:../../install_config/router/index.adoc#install-config-router-overview[Deploying a Router].
endif::[]

[[haproxy-template-router]]

=== HAProxy Template Router

The HAProxy template router implementation is the reference implementation for a
template router plug-in. It uses the
ifdef::openshift-enterprise,openshift-dedicated[]
*openshift3/ose-haproxy-router*
endif::[]
ifdef::openshift-origin[]
*openshift/origin-haproxy-router*
endif::[]
repository to run an HAProxy instance alongside the template router plug-in.

The following diagram illustrates how data flows from the master through the
plug-in and finally into an HAProxy configuration:

.HAProxy Router Data Flow
image::router_model.png[HAProxy Router Data Flow]

[[routes-sticky-sessions]]
=== Sticky Sessions

include::architecture/topics/sticky_sessions.adoc[]

[[env-variables]]
include::architecture/topics/router_environment_variables.adoc[]

[[f5-router]]
=== F5 Router

ifdef::openshift-enterprise[]
[NOTE]
====
The F5 router plug-in is available starting in OpenShift Enterprise 3.0.2.
====
endif::[]

The F5 router plug-in integrates with an existing *F5 BIG-IP®* system in your
environment. *F5 BIG-IP®* version 11.4 or newer is required in order to have the
F5 iControl REST API. The F5 router supports xref:route-types[unsecured],
xref:edge-termination[edge terminated],
xref:re-encryption-termination[re-encryption terminated], and
xref:passthrough-termination[passthrough terminated] routes matching on HTTP
vhost and request path.

The F5 router has feature parity with the
xref:haproxy-template-router[HAProxy template router],
and has additional features over the *F5 BIG-IP®* support in
ifdef::openshift-enterprise[]
OpenShift Enterprise 2.
endif::[]
ifdef::openshift-origin[]
OpenShift v2.
endif::[]
Compared with the *routing-daemon* used in earlier
versions, the F5 router additionally supports:

- path-based routing (using policy rules),
- re-encryption (implemented using client and server SSL profiles), and
- passthrough of encrypted connections (implemented using an iRule that parses
the SNI protocol and uses a data group that is maintained by the F5 router for
the servername lookup).

[NOTE]
====
Passthrough routes are a special case: path-based routing is technically
impossible with passthrough routes because *F5 BIG-IP®* itself does not see the
HTTP request, so it cannot examine the path. The same restriction applies to the
template router; it is a technical limitation of passthrough encryption, not a
technical limitation of {product-title}.
====

[[routing-traffic-to-pods-through-the-sdn]]
==== Routing Traffic to Pods Through the SDN

Because *F5 BIG-IP®* is external to the {product-title} SDN, a
cluster administrator must create a peer-to-peer tunnel between *F5 BIG-IP®* and
a host that is on the SDN, typically an {product-title} node host.
ifdef::openshift-dedicated[]
This _ramp node_ can be configured as unschedulable for pods so that it will not
be doing anything except act as a gateway for the *F5 BIG-IP®* host.
endif::[]
ifdef::openshift-enterprise,openshift-origin[]
This
xref:../../install_config/routing_from_edge_lb.adoc#establishing-a-tunnel-using-a-ramp-node[_ramp
node_] can be configured as
xref:../../admin_guide/manage_nodes.adoc#marking-nodes-as-unschedulable-or-schedulable[unschedulable]
for pods so that it will not be doing anything except act as a gateway for the
*F5 BIG-IP®* host.
endif::[]
It is also possible to configure multiple such hosts and use
the {product-title} *ipfailover* feature for redundancy; the *F5 BIG-IP®* host would
then need to be configured to use the *ipfailover* VIP for its tunnel's remote
endpoint.

[[f5-integration-details]]
==== F5 Integration Details

The operation of the F5 router is similar to that of the {product-title}
*routing-daemon* used in earlier versions. Both use REST API calls to:

- create and delete pools,
- add endpoints to and delete them from those pools, and
- configure policy rules to route to pools based on vhost.

Both also use `scp` and `ssh` commands to upload custom TLS/SSL certificates to
*F5 BIG-IP®*.

The F5 router configures pools and policy rules on virtual servers as follows:

- When a user creates or deletes a route on {product-title}, the router creates a
pool to *F5 BIG-IP®* for the route (if no pool already exists) and adds a rule to, or
deletes a rule from, the policy of the appropriate vserver: the HTTP vserver for
non-TLS routes, or the HTTPS vserver for edge or re-encrypt routes. In the case
of edge and re-encrypt routes, the router also uploads and configures the TLS
certificate and key. The router supports host- and path-based routes.
+
[NOTE]
====
Passthrough routes are a special case: to support those, it is necessary to
write an iRule that parses the SNI ClientHello handshake record and looks up the
servername in an F5 data-group. The router creates this iRule, associates the
iRule with the vserver, and updates the F5 data-group as passthrough routes are
created and deleted. Other than this implementation detail, passthrough routes
work the same way as other routes.
====

- When a user creates a service on {product-title}, the router adds a pool to *F5
BIG-IP®* (if no pool already exists). As endpoints on that service are created
and deleted, the router adds and removes corresponding pool members.

- When a user deletes the route and all endpoints associated with a particular
pool, the router deletes that pool.

[[architecture-f5-native-integration]]
==== F5 Native Integration

With native integration of F5 with {product-title}], you do not need to configure a ramp
node for F5 to be able to reach the pods on the overlay network as created by
OpenShift SDN.

*Connection*

The F5 appliance can connect to the {product-title} cluster via an L3
connection. An L2 switch connectivity is not required between {product-title}
nodes. On the appliance, you can use multiple interfaces to manage the
integration:

* Management interface - Reaches the web console of the F5 appliance.
* External interface - Configures the virtual servers for inbound web traffic.
* Internal interface - Programs the appliance and reaches out to the pods.

image::F5-OpenShift-Connection-Diagram.png[F5 and OpenShift Connection Diagram]

An F5 controller pod has `admin` access to the appliance. The F5 image is
launched within the {product-title} cluster (scheduled on any node) that uses
iControl REST APIs to program the virtual servers with policies, and configure
the VxLAN device.

*Data Flow: Packets to Pods*

[NOTE]
====
This section explains how the packets reach the pods, and vice versa. These
actions are performed by the F5 controller pod and the F5 appliance, not the
user.
====

When natively integrated, The F5 appliance reaches out to the pods directly
using VxLAN encapsulation. This integration works only when {product-title} is
using *openshift-sdn* as the network plug-in. The *openshift-sdn*  plug-in
employs VxLAN encapsulation for the overlay network that it creates.

To make a successful data path between a pod and the F5 appliance:

. F5 needs to encapsulate the VxLAN packet meant for the pods. This requires the
*sdn-services* license add-on. A VxLAN device needs to be created and the pod
overlay network needs to be routed through this device.

. F5 needs to know the VTEP IP address of the pod, which is the IP address of the
node where the pod is located.

. F5 needs to know which `source-ip` to use for the overlay network when
encapsulating the packets meant for the pods. This is known as the _gateway address_.

. {product-title} nodes need to know where the F5 gateway address is (the VTEP
address for the return traffic). This needs to be the internal interface’s
address. All nodes of the cluster must learn this automatically.

. Since the overlay network is multi-tenant aware, F5 must use a VxLAN ID that is
representative of an `admin` domain, ensuring that all tenants are reachable by
the F5. Ensure that F5 encapsulates all packets with a `vnid` of `0` (the
default `vnid` for the `admin` namespace in {product-title}) by putting an
annotation on the manually created `hostsubnet` -
`pod.network.openshift.io/fixed-vnid-host: 0`.

A ghost `hostsubnet` is manually created as part of the setup, which fulfills
the third and forth listed requirements. When the F5 controller pod is launched,
this new ghost `hostsubnet` is provided so that the F5 appliance can be
programmed suitably.

[NOTE]
====
The term _ghost_ `hostsubnet` is used because it suggests that a subnet has been
given to a node of the cluster. However, in reality, it is not a real node of
the cluster. It is hijacked by an external appliance.
====

The first requirement is fulfilled by the F5 controller pod once it is launched.
The second requirement is also fulfilled by the F5 controller pod, but it is an
ongoing process. For each new node that is added to the cluster, the controller
pod creates an entry in the VxLAN device’s VTEP FDB. The controller pod needs
access to the `nodes` resource in the cluster, which you can accomplish by
giving the service account appropriate privileges. Use the following command:

----
$ oadm policy add-cluster-role-to-user system:sdn-reader system:serviceaccount:default:router
----

*Data Flow from the F5 Host*

[NOTE]
====
These actions are performed by the F5 controller pod and the F5 appliance, not
the user.
====

. The destination pod is identified by the F5 virtual server for a packet.

. VxLAN dynamic FDB is looked up with pod’s IP address. If a MAC address is found, go to step 5.

. Flood all entries in the VTEP FDB with ARP requests seeking the pod’s MAC address.

. One of the nodes (VTEP) will respond, confirming that it is the one where the
pod is located. An entry is made into the VxLAN dynamic FDB with the pod’s MAC
address and the VTEP to be used as the value.

. Encap an IP packet with VxLAN headers, where the MAC of the pod and the VTEP of
the node is given as values from the VxLAN dynamic FDB.

. Calculate the VTEP's MAC address by sending out an ARP or checking the host’s
neighbor cache.

. Deliver the packet through the F5 host’s internal address.

*Data Flow: Return Traffic to the F5 Host*

[NOTE]
====
These actions are performed by the F5 controller pod and the F5 appliance, not
the user.
====

. The pod sends back a packet with the destination as the F5 host’s VxLAN gateway address.

. The `openvswitch` at the node determines that the VTEP for this packet is the
 F5 host’s internal interface address. This is learned from the ghost `hostsubnet`
 creation.

. A VxLAN packet is sent out to the internal interface of the F5 host.

[NOTE]
====
During the entire data flow, the VNID is pre-fixed to be `0` to bypass multi-tenancy.
====

[[route-hostnames]]

== Route Host Names
In order for services to be exposed externally, an {product-title} route allows
you to associate a service with an externally-reachable host name. This edge
host name is then used to route traffic to the service.

When multiple routes from different namespaces claim the same host,
the oldest route wins and claims it for the namespace. If additional
routes with different path fields are defined in the same namespace,
those paths are added. If multiple routes with the same path are
used, the oldest takes priority.

A consequence of this behavior is that if you have two routes for a host name: an
older one and a newer one. If someone else has a route for the same host name
that they created between when you created the other two routes, then if you
delete your older route, your claim to the host name will no longer be in effect.
The other namespace now claims the host name and your claim is lost.

.A Route with a Specified Host:
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: host-route
spec:
  host: www.example.com  <1>
  to:
    kind: Service
    name: service-name
----
<1> Specifies the externally-reachable host name used to expose a service.
====

.A Route Without a Host:
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: no-route-hostname
spec:
  to:
    kind: Service
    name: service-name
----
====

If a host name is not provided as part of the route definition, then
{product-title} automatically generates one for you. The generated host name
is of the form:

----
<route-name>[-<namespace>].<suffix>
----

The following example shows the {product-title}-generated host name for the
above configuration of a route without a host added to a namespace
*mynamespace*:

.Generated Host Name
====

----
no-route-hostname-mynamespace.router.default.svc.cluster.local <1>
----
<1> The generated host name suffix is the default routing subdomain
*router.default.svc.cluster.local*.
====

A cluster administrator can also
ifdef::openshift-enterprise,openshift-origin[]
xref:../../install_config/router/default_haproxy_router.adoc#customizing-the-default-routing-subdomain[customize
the suffix used as the default routing subdomain]
endif::[]
ifdef::openshift-dedicated[]
customize the suffix used as the default routing subdomain
endif::[]
for their environment.

[[route-types]]
== Route Types
Routes can be either secured or unsecured. Secure routes provide the ability to
use several types of TLS termination to serve certificates to the client.
Routers support xref:edge-termination[edge],
xref:passthrough-termination[passthrough], and
xref:re-encryption-termination[re-encryption] termination.

.Unsecured Route Object YAML Definition
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-unsecured
spec:
  host: www.example.com
  to:
    kind: Service
    name: service-name
----

====

Unsecured routes are simplest to configure, as they require no key
or certificates, but secured routes offer security for connections to
remain private.

A secured route is one that specifies the TLS termination of the route.
The available types of termination are xref:secured-routes[described
below].

[[path-based-routes]]
== Path Based Routes
Path based routes specify a path component that can be compared against
a URL (which requires that the traffic for the route be HTTP based) such
that multiple routes can be served using the same host name, each with a
different path. Routers should match routes based on the most specific
path to the least; however, this depends on the router implementation. The
following table shows example routes and their accessibility:

.Route Availability
[cols="3*", options="header"]
|===
|Route |When Compared to |Accessible

.2+|_www.example.com/test_ |_www.example.com/test_ |Yes

|_www.example.com_ |No

.2+|_www.example.com/test_ and _www.example.com_ |_www.example.com/test_ |Yes

|_www.example.com_ |Yes

.2+|_www.example.com_ |_www.example.com/test_ |Yes (Matched by the host, not the route)

|_www.example.com_ |Yes
|===

.An Unsecured Route with a Path:
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-unsecured
spec:
  host: www.example.com
  path: "/test"   <1>
  to:
    kind: Service
    name: service-name
----

<1> The path is the only added attribute for a path-based route.
====

[NOTE]
====
Path-based routing is not available when using passthrough TLS, as
the router does not terminate TLS in that case and cannot read the contents
of the request.
====

[[secured-routes]]
== Secured Routes
Secured routes specify the TLS termination of the route and, optionally,
provide a key and certificate(s).

[NOTE]
====
TLS termination in {product-title} relies on
link:https://en.wikipedia.org/wiki/Server_Name_Indication[SNI] for serving
custom certificates. Any non-SNI traffic received on port 443 is handled with
TLS termination and a default certificate (which may not match the requested
host name, resulting in validation errors).
====

Secured routes can use any of the following three types of secure TLS
termination.

[[edge-termination]]
*Edge Termination*

With edge termination, TLS termination occurs at the router, prior to proxying
traffic to its destination. TLS certificates are served by the front end of the
router, so they must be configured into the route, otherwise the
ifdef::openshift-enterprise,openshift-origin[]
xref:../../install_config/router/default_haproxy_router.adoc#using-wildcard-certificates[router's
default certificate]
endif::[]
ifdef::openshift-dedicated[]
router's default certificate
endif::[]
will be used for TLS termination.

.A Secured Route Using Edge Termination
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-edge-secured <1>
spec:
  host: www.example.com
  to:
    kind: Service
    name: service-name <1>
  tls:
    termination: edge            <2>
    key: |-                      <3>
      -----BEGIN PRIVATE KEY-----
      [...]
      -----END PRIVATE KEY-----
    certificate: |-              <4>
      -----BEGIN CERTIFICATE-----
      [...]
      -----END CERTIFICATE-----
    caCertificate: |-            <5>
      -----BEGIN CERTIFICATE-----
      [...]
      -----END CERTIFICATE-----
----
<1> The name of the object, which is limited to 63 characters.
<2> The `*termination*` field is `edge` for edge termination.
<3> The `*key*` field is the contents of the PEM format key file.
<4> The `*certificate*` field is the contents of the PEM format certificate file.
<5> An optional CA certificate may be required to establish a certificate chain for validation.
====

Because TLS is terminated at the router, connections from the router to
the endpoints over the internal network are not encrypted.

Edge-terminated routes can specify an `insecureEdgeTerminationPolicy` that
enables traffic on insecure schemes (`HTTP`) to be disabled, allowed or
redirected.
The allowed values for `insecureEdgeTerminationPolicy` are:
  `None` or empty (for disabled), `Allow` or `Redirect`.
The default `insecureEdgeTerminationPolicy` is to disable traffic on the
insecure scheme. A common use case is to allow content to be served via a
secure scheme but serve the assets (example images, stylesheets and
javascript) via the insecure scheme.

.A Secured Route Using Edge Termination Allowing HTTP Traffic
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-edge-secured-allow-insecure <1>
spec:
  host: www.example.com
  to:
    kind: Service
    name: service-name <1>
  tls:
    termination:                   edge   <2>
    insecureEdgeTerminationPolicy: Allow  <3>
    [ ... ]
----
<1> The name of the object, which is limited to 63 characters.
<2> The `*termination*` field is `edge` for edge termination.
<3> The insecure policy to allow requests sent on an insecure scheme `HTTP`.
====

.A Secured Route Using Edge Termination Redirecting HTTP Traffic to HTTPS
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-edge-secured-redirect-insecure <1>
spec:
  host: www.example.com
  to:
    kind: Service
    name: service-name <1>
  tls:
    termination:                   edge      <2>
    insecureEdgeTerminationPolicy: Redirect  <3>
    [ ... ]
----
<1> The name of the object, which is limited to 63 characters.
<2> The `*termination*` field is `edge` for edge termination.
<3> The insecure policy to redirect requests sent on an insecure scheme `HTTP` to a secure scheme `HTTPS`.
====

[[passthrough-termination]]
*Passthrough Termination*

With passthrough termination, encrypted traffic is sent straight to the
destination without the router providing TLS termination. Therefore no
key or certificate is required.

.A Secured Route Using Passthrough Termination
====
[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-passthrough-secured <1>
spec:
  host: www.example.com
  to:
    kind: Service
    name: service-name <1>
  tls:
    termination: passthrough     <2>
----
<1> The name of the object, which is limited to 63 characters.
<2> The `*termination*` field is set to `passthrough`. No other encryption fields are needed.
====

The destination pod is responsible for serving certificates for the
traffic at the endpoint. This is currently the only method that can support
requiring client certificates (also known as two-way authentication).

[NOTE]
====
passthrough routes can also have an `insecureEdgeTerminationPolicy` the only valid values are
`None` or empty (for disabled) or `Redirect`.
====

[[re-encryption-termination]]
*Re-encryption Termination*

Re-encryption is a variation on edge termination where the router terminates
TLS with a certificate, then re-encrypts its connection to the endpoint which
may have a different certificate. Therefore the full path of the connection
is encrypted, even over the internal network. The router uses health
checks to determine the authenticity of the host.


.A Secured Route Using Re-Encrypt Termination
====

[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  name: route-pt-secured <1>
spec:
  host: www.example.com
  to:
    kind: Service
    name: service-name <1>
  tls:
    termination: reencrypt        <2>
    key: [as in edge termination]
    certificate: [as in edge termination]
    caCertificate: [as in edge termination]
    destinationCACertificate: |-  <3>
      -----BEGIN CERTIFICATE-----
      [...]
      -----END CERTIFICATE-----
----

<1> The name of the object, which is limited to 63 characters.
<2> The `*termination*` field is set to `reencrypt`. Other fields are as in edge
termination.
<3> The `*destinationCACertificate*` field specifies a CA certificate to
validate the endpoint certificate, securing the connection from the router to
the destination. This field is required, but only for re-encryption.
====


[[router-sharding]]
== Router Sharding
include::architecture/topics/router_sharding.adoc[]

[[alternateBackends]]
== Alternate Backends and Weights
include::architecture/topics/alternate_backends_weights.adoc[]

[[route-specific-annotations]]
== Route-specific Annotations

Using environment variables as defined in xref:env-variables[Configuration
Parameters], a router can set the default options for all the routes it exposes.
An individual route can override some of these defaults by providing specific
configurations in its annotations.

*Route Annotations*

For all the items outlined in this section, you can set annotations on the
*route definition* for the route to alter its configuration

.Route Annotations
[cols="3*", options="header"]
|===
|Variable | Description | Environment Variable Used as Default
|`*haproxy.router.openshift.io/balance*`| Sets the xref:load-balancing[load-balancing algorithm]. Available options are `source`, `roundrobin`, and `leastconn`. | `ROUTER_TCP_BALANCE_SCHEME` for passthrough routes. Otherwise, use `ROUTER_LOAD_BALANCE_ALGORITHM`.
|`*haproxy.router.openshift.io/disable_cookies*`| Disables the use of cookies to track related connections. If set to `true` or `TRUE`, the balance algorithm is used to choose which back-end serves connections for each incoming HTTP request. |
|`*haproxy.router.openshift.io/cookie_name*`| Specifies an optional cookie to be used for
this route. The name must consist of any combination of upper and lower case letters, digits, "_",
and "-". The default is the hashed internal key name for the route. |
|`*haproxy.router.openshift.io/rate-limit-connections*`| Setting `true` or `TRUE` to enables rate limiting functionality. |
|`*haproxy.router.openshift.io/rate-limit-connections.concurrent-tcp*`| Limits the number of concurrent TCP connections shared by an IP address. |
|`*haproxy.router.openshift.io/rate-limit-connections.rate-http*`| Limits the rate at which an IP address can make HTTP requests. |
|`*haproxy.router.openshift.io/rate-limit-connections.rate-tcp*`| Limits the rate at which an IP address can make TCP connections. |
|`*haproxy.router.openshift.io/timeout*` | Sets a server-side timeout. | `ROUTER_DEFAULT_SERVER_TIMEOUT`
|`*router.openshift.io/haproxy.health.check.interval*`| Sets the interval for the back-end health checks. | `ROUTER_BACKEND_CHECK_INTERVAL`
|===


.A Route Setting Custom Timeout
[source,yaml]
----
apiVersion: v1
kind: Route
metadata:
  annotations:
    haproxy.router.openshift.io/timeout: 5500ms <1>
[...]
----
<1> Specifies the new timeout with HAProxy supported units (us, ms, s, m, h, d).
If unit not provided, ms is the default.

[NOTE]
====
Setting a server-side timeout value for passthrough routes too low can cause
WebSocket connections to timeout frequently on that route.
====


[[wildcard-subdomain-route-policy]]
== Creating Routes Specifying a Wildcard Subdomain Policy

A wildcard policy allows a user to define a route that covers all hosts within a
domain (when the router is configured to allow it). A route can specify a
wildcard policy as part of its configuration using the `wildcardPolicy` field.
Any routers run with a policy allowing wildcard routes will expose the route
appropriately based on the wildcard policy.

// xref:../../install_config/router/default_haproxy_router.adoc#using-wildcard-routes[Learn how to configure HAProxy routers to allow wildcard routes].

.A Route Specifying a Subdomain WildcardPolicy
[source,yaml]
----
apiVersion: v1
kind: Route
spec:
  host: wildcard.example.com  <1>
  wildcardPolicy: Subdomain   <2>
  to:
    kind: Service
    name: service-name
----
<1> Specifies the externally reachable host name used to expose a service.
<2> Specifies that the externally reachable host name should allow all hosts
    in the subdomain `example.com`. `*.example.com` is the subdomain for host
    name `wildcard.example.com` to reach the exposed service.

[[route-status-field]]
== Route Status

The `route status` field is only set by routers. If changes are made to a route
so that a router no longer serves a specific route, the status becomes stale.
The routers do not clear the `route status` field. To remove the stale entries
in the route status, use the
link:https://github.com/openshift/origin/blob/master/images/router/clear-route-status.sh[clear-route-status
script].

[[architecture-core-concepts-routes-deny-allow]]
== Denying or Allowing Certain Domains in Routes

A router can be configured to deny or allow a specific subset of domains from
the host names in a route using the `ROUTER_DENIED_DOMAINS` and
`ROUTER_ALLOWED_DOMAINS` environment variables.

[cols="2"]
|===

|`*ROUTER_DENIED_DOMAINS*` | Domains listed are not allowed in any indicated routes.
|`*ROUTER_ALLOWED_DOMAINS*` | Only the domains listed are allowed in any indicated routes.

|===

The domains in the list of denied domains take precedence over the list of
allowed domains. Meaning {product-title} first checks the deny list (if
applicable), and if the host name is not in the list of denied domains, it then
checks the list of allowed domains. However, the list of allowed domains is more
restrictive, and ensures that the router only admits routes with hosts that
belong to that list.

For example, to deny the `[*.]open.header.test`, `[*.]openshift.org` and
`[*.]block.it` routes for the `myrouter` route:

----
$ oadm router myrouter ...
$ oc set env dc/myrouter ROUTER_DENIED_DOMAINS="open.header.test, openshift.org, block.it"
----

This means that `myrouter` will admit the following based on the route's name:

----
$ oc expose service/<name> --hostname="foo.header.test"
$ oc expose service/<name> --hostname="www.allow.it"
$ oc expose service/<name> --hostname="www.openshift.test"
----

However, `myrouter` will deny the following:

----
$ oc expose service/<name> --hostname="open.header.test"
$ oc expose service/<name> --hostname="www.open.header.test"
$ oc expose service/<name> --hostname="block.it"
$ oc expose service/<name> --hostname="franco.baresi.block.it"
$ oc expose service/<name> --hostname="openshift.org"
$ oc expose service/<name> --hostname="api.openshift.org"
----

Alternatively, to block any routes where the host name is _not_ set to `[*.]stickshift.org` or `[*.]kates.net`:

----
$ oadm router myrouter ...
$ oc set env dc/myrouter ROUTER_ALLOWED_DOMAINS="stickshift.org, kates.net"
----

This means that the `myrouter` router will admit:

----
$ oc expose service/<name> --hostname="stickshift.org"
$ oc expose service/<name> --hostname="www.stickshift.org"
$ oc expose service/<name> --hostname="kates.net"
$ oc expose service/<name> --hostname="api.kates.net"
$ oc expose service/<name> --hostname="erno.r.kube.kates.net"
----

However, `myrouter` will deny the following:

----
$ oc expose service/<name> --hostname="www.open.header.test"
$ oc expose service/<name> --hostname="drive.ottomatic.org"
$ oc expose service/<name> --hostname="www.wayless.com"
$ oc expose service/<name> --hostname="www.deny.it"
----

To implement both scenarios, run:

----
$ oadm router adrouter ...
$ oc env dc/adrouter ROUTER_ALLOWED_DOMAINS="openshift.org, kates.net" \
    ROUTER_DENIED_DOMAINS="ops.openshift.org, metrics.kates.net"
----

This will allow any routes where the host name is set to `[*.]openshift.org` or
`[*.]kates.net`, and not allow any routes where the host name is set to
`[*.]ops.openshift.org` or `[*.]metrics.kates.net`.

Therefore, the following will be denied:

----
$ oc expose service/<name> --hostname="www.open.header.test"
$ oc expose service/<name> --hostname="ops.openshift.org"
$ oc expose service/<name> --hostname="log.ops.openshift.org"
$ oc expose service/<name> --hostname="www.block.it"
$ oc expose service/<name> --hostname="metrics.kates.net"
$ oc expose service/<name> --hostname="int.metrics.kates.net"
----

However, the following will be allowed:

----
$ oc expose service/<name> --hostname="openshift.org"
$ oc expose service/<name> --hostname="api.openshift.org"
$ oc expose service/<name> --hostname="m.api.openshift.org"
$ oc expose service/<name> --hostname="kates.net"
$ oc expose service/<name> --hostname="api.kates.net"
----
